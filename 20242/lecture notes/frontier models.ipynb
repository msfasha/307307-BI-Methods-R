{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the updated lecture incorporating **DeepSeek** while keeping all previously included information.\n",
    "\n",
    "---\n",
    "\n",
    "# **Frontier Large Language Models (LLMs)**  \n",
    "\n",
    "## **1. Introduction to LLMs**\n",
    "Large Language Models (LLMs) are AI models trained on vast amounts of text data to generate human-like text, assist in various tasks, and power AI-driven applications. Some of the most advanced LLMs today come from leading AI research labs, each offering unique architectures, capabilities, and use cases.\n",
    "\n",
    "This lecture covers the major LLMs, their features, differences, and code examples to interact with them.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Major Frontier LLMs & Their Developers**\n",
    "\n",
    "| Company       | Model(s)         | Chat Interface    | Key Features |\n",
    "|--------------|-----------------|------------------|--------------|\n",
    "| **OpenAI**   | GPT-4, GPT-4-turbo, GPT-3.5 | ChatGPT | Strong reasoning, multimodal (text & image in GPT-4), API for developers |\n",
    "| **Anthropic** | Claude 1, 2, 3  | Claude | Focus on safety, long-context handling, efficient responses |\n",
    "| **Google**    | Gemini 1, Gemini 1.5 | Gemini Advance | Strong in reasoning, image understanding, Google search integration |\n",
    "| **Cohere**    | Command R+, Command R | Cohere API | Enterprise-focused, retrieval-augmented generation (RAG) |\n",
    "| **Meta**      | LLaMA 2, LLaMA 3 (upcoming) | meta.ai | Open-source, efficient models for researchers |\n",
    "| **Perplexity**| Perplexity AI | Search-integrated LLM | AI-powered search engine, real-time web browsing |\n",
    "| **DeepSeek**  | DeepSeek LLM, DeepSeek Coder | DeepSeek API | Open-source, optimized for code generation and general-purpose AI |\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Key Capabilities & Differentiators**\n",
    "\n",
    "### **ðŸ”¹ OpenAI (GPT-4, GPT-4-turbo)**\n",
    "- Best for general-purpose AI tasks.\n",
    "- Offers **ChatGPT** with an API.\n",
    "- **Multimodal capabilities** (text & image inputs).\n",
    "- **Fine-tuning & plugins** support.\n",
    "\n",
    "ðŸ”¹ **Use Case: Calling GPT-4 API**\n",
    "```python\n",
    "import openai\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of Jordan?\"}]\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **ðŸ”¹ Anthropic (Claude)**\n",
    "- Known for **long-context understanding** (100k+ tokens).\n",
    "- **Safety-focused**, fine-tuned for responsible AI.\n",
    "- Claude 3 is expected to compete directly with GPT-4.\n",
    "\n",
    "ðŸ”¹ **Use Case: Calling Claude API**\n",
    "```python\n",
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(api_key=\"your_api_key\")\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-2\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Summarize the theory of relativity\"}]\n",
    ")\n",
    "print(response.content)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **ðŸ”¹ Google Gemini**\n",
    "- Strong in **multimodal (text, images, video) processing**.\n",
    "- **Optimized for reasoning tasks** like math & coding.\n",
    "- Integrated with **Google products** (Docs, Search).\n",
    "\n",
    "ðŸ”¹ **Use Case: Calling Gemini API**\n",
    "```python\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"your_google_api_key\")\n",
    "\n",
    "response = genai.chat(\"Explain black holes in simple terms.\")\n",
    "print(response.text)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **ðŸ”¹ Cohere (Command R+)**\n",
    "- Focused on **enterprise AI** with **RAG (Retrieval-Augmented Generation)**.\n",
    "- **Memory** and fine-tuning options for custom enterprise use.\n",
    "\n",
    "ðŸ”¹ **Use Case: Calling Cohere API**\n",
    "```python\n",
    "import cohere\n",
    "\n",
    "co = cohere.Client('your_api_key')\n",
    "\n",
    "response = co.generate(\n",
    "    model='command-r',\n",
    "    prompt=\"Write a business report about AI adoption trends.\",\n",
    "    max_tokens=300\n",
    ")\n",
    "print(response.generations[0].text)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **ðŸ”¹ Meta (LLaMA)**\n",
    "- **Open-source LLM** for researchers & developers.\n",
    "- **Optimized for fine-tuning & edge deployment**.\n",
    "\n",
    "ðŸ”¹ **Use Case: Running LLaMA Locally with Hugging Face**\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"What are the benefits of AI in healthcare?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n",
    "print(tokenizer.decode(outputs[0]))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **ðŸ”¹ Perplexity AI**\n",
    "- **AI-powered search engine**, similar to ChatGPT with real-time web browsing.\n",
    "- **Not a traditional chatbot**â€”it **retrieves live data** instead of static knowledge.\n",
    "\n",
    "ðŸ”¹ **Use Case: Using Perplexity AI Search**\n",
    "Perplexity does not have a public API but is mainly used through its website.\n",
    "\n",
    "---\n",
    "\n",
    "### **ðŸ”¹ DeepSeek AI**\n",
    "- Focuses on **open-source AI development**.\n",
    "- Provides **DeepSeek LLM** for general-purpose AI.\n",
    "- **DeepSeek Coder** is optimized for **code generation and programming tasks**.\n",
    "- Competes with models like **Code LLaMA and GPT-4 Code Interpreter**.\n",
    "\n",
    "ðŸ”¹ **Use Case: Running DeepSeek Locally with Hugging Face**\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-coder-6.7b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"Write a Python function to sort a list using merge sort.\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Choosing the Right LLM**\n",
    "| **Use Case**        | **Best LLM** |\n",
    "|---------------------|-------------|\n",
    "| General AI Chatbot | GPT-4, Claude 2 |\n",
    "| Long-context tasks | Claude 2, GPT-4 |\n",
    "| Multimodal AI (Images, Video) | Gemini 1.5, GPT-4 |\n",
    "| Enterprise & RAG | Cohere Command R+ |\n",
    "| Open-Source Model | LLaMA 2, DeepSeek |\n",
    "| AI Search Engine | Perplexity AI |\n",
    "| AI for Coding | DeepSeek Coder, GPT-4 Code Interpreter |\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Conclusion**\n",
    "Frontier LLMs are evolving rapidly, each optimized for different capabilities:\n",
    "- **OpenAI GPT** â†’ General-purpose, multimodal, best reasoning.\n",
    "- **Anthropic Claude** â†’ Safety-focused, long-context handling.\n",
    "- **Google Gemini** â†’ Multimodal, Google integration.\n",
    "- **Cohere Command R+** â†’ Enterprise applications, retrieval-based AI.\n",
    "- **Meta LLaMA** â†’ Open-source, fine-tuning flexibility.\n",
    "- **Perplexity AI** â†’ Real-time AI-powered search.\n",
    "- **DeepSeek** â†’ Strong in open-source AI, specialized coding model.\n",
    "\n",
    "For developers, choosing an LLM depends on **specific needs**, whether it's **general AI conversations, enterprise AI, multimodal processing, code generation, or open-source flexibility**.\n",
    "\n",
    "---\n",
    "\n",
    "This version includes **DeepSeek AI** while preserving all previously mentioned details. Let me know if you'd like further refinements! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
