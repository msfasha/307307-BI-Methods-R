{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msfasha/307307-BI-Methods-LLMs/blob/main/section_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZo4Cyqf_w-B"
      },
      "source": [
        "### **Introduction to Natural Language Processing (NLP)**\n",
        "\n",
        "#### **1.1 What is NLP?**\n",
        "Natural Language Processing (NLP) is a field of Artificial Intelligence (AI) that enables computers to understand, interpret, and generate human language.<br> NLP bridges the gap between human communication and machine understanding, allowing businesses to analyze and leverage text data effectively.\n",
        "\n",
        "**Applications of NLP in Business:**\n",
        "1. **Customer Insights:** Sentiment analysis of customer reviews and feedback.\n",
        "2. **Automation:** Automated chatbots for customer support.\n",
        "3. **Content Generation:** Writing articles, generating reports, or creating marketing content.\n",
        "4. **Decision Support:** Extracting insights from financial reports, contracts, and legal documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c3hpLCu_w-E"
      },
      "source": [
        "#### **1.2 Core Concepts in NLP**\n",
        "\n",
        "**1.2.1 Text Preprocessing**  \n",
        "Preprocessing prepares raw text data for analysis by cleaning and standardizing it. This step is critical because raw text contains noise like punctuation, special characters, and inconsistencies.\n",
        "\n",
        "**Steps of Text Preprocessing with Code:**\n",
        "\n",
        "1. **Tokenization:** Breaking text into smaller components, such as words or sentences.\n",
        "2. **Removing Stopwords:** Filtering out common words (e.g., \"is,\" \"the\") that don’t contribute much meaning.\n",
        "3. **Stemming and Lemmatization:** Reducing words to their root form for consistency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Python Code Example:**\n",
        "\n",
        "First of all, we need to install NLTN, Python main NLP library.<br>\n",
        "The Natural Language Toolkit (NLTK) is a comprehensive library for natural language processing (NLP) in Python. It provides easy-to-use interfaces to over 50 corpora and lexical resources, such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning.<br> NLTK also includes wrappers for industrial-strength NLP libraries. It is widely used for research and educational purposes due to its simplicity and extensive documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orFLKmRW_w-E",
        "outputId": "9ee75d3d-93e0-45b4-83de-d1ac9e34ee38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click (from nltk)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: joblib in /home/me/myenv/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m406.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting tqdm (from nltk)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm, regex, click, nltk\n",
            "Successfully installed click-8.1.8 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n"
          ]
        }
      ],
      "source": [
        "! pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_NPnEwJ_w-K"
      },
      "source": [
        "**Example text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "# Download the 'punkt_tab' resource\n",
        "nltk.download('punkt_tab')  # This line is added to download the necessary resource\n",
        "\n",
        "# Download other required resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "text = \"Natural Language Processing is an exciting field of Artificial Intelligence!\"\n",
        "\n",
        "# 1. Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# 2. Removing Stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(\"Filtered Tokens:\", filtered_tokens)\n",
        "\n",
        "# 3. Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
        "\n",
        "# 4. Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "print(\"Lemmatized Tokens:\", lemmatized_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYmEwj06_w-N"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8FSQo5Z_w-P"
      },
      "source": [
        "**1.2.2 Bag of Words (BoW) and TF-IDF**  \n",
        "BoW and TF-IDF are techniques to convert text into numerical vectors for machine learning.\n",
        "\n",
        "**Bag of Words:**\n",
        "- Counts the frequency of words in a document.\n",
        "- Doesn't consider the importance or meaning of words.\n",
        "\n",
        "**TF-IDF (Term Frequency-Inverse Document Frequency):**\n",
        "- Assigns weights to words based on their frequency in a document and across all documents.\n",
        "\n",
        "**Python Code Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_me1aYl_w-Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bag of Words Matrix:\n",
            "[[1 0 0 0 0 1 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 1 1 1 0 1 1 0]\n",
            " [0 0 1 1 1 0 1 0 1 0 0 1]]\n",
            "Feature Names: ['amazing' 'future' 'helps' 'human' 'in' 'is' 'language' 'natural' 'nlp'\n",
            " 'processing' 'the' 'understanding']\n",
            "\n",
            "TF-IDF Matrix:\n",
            "[[0.68091856 0.         0.         0.         0.         0.51785612\n",
            "  0.         0.         0.51785612 0.         0.         0.        ]\n",
            " [0.         0.44036207 0.         0.         0.         0.3349067\n",
            "  0.3349067  0.44036207 0.         0.44036207 0.44036207 0.        ]\n",
            " [0.         0.         0.44036207 0.44036207 0.44036207 0.\n",
            "  0.3349067  0.         0.3349067  0.         0.         0.44036207]]\n",
            "Feature Names: ['amazing' 'future' 'helps' 'human' 'in' 'is' 'language' 'natural' 'nlp'\n",
            " 'processing' 'the' 'understanding']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Sample text data\n",
        "documents = [\n",
        "    \"NLP is amazing.\",\n",
        "    \"Natural Language Processing is the future.\",\n",
        "    \"NLP helps in understanding human language.\"\n",
        "]\n",
        "\n",
        "# Bag of Words\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(documents)\n",
        "print(\"Bag of Words Matrix:\")\n",
        "print(bow_matrix.toarray())\n",
        "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
        "\n",
        "# TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "print(\"\\nTF-IDF Matrix:\")\n",
        "print(tfidf_matrix.toarray())\n",
        "print(\"Feature Names:\", tfidf_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsSx4KzT_w-R"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y0FSSjA_w-R"
      },
      "source": [
        "#### **1.3 Introduction to Vectors**\n",
        "\n",
        "**Definition:**  \n",
        "A **vector** is a mathematical object that has both magnitude (size) and direction. In NLP, vectors are used to represent words, sentences, or documents as points in a multi-dimensional space. Understanding vectors is crucial for understanding word embeddings.\n",
        "\n",
        "**1.3.1 Why Are Vectors Important in NLP?**\n",
        "1. **Representation:** Words and phrases can be represented as numerical vectors, enabling mathematical operations.\n",
        "2. **Similarity:** Vectors help measure similarity between words (e.g., cosine similarity).\n",
        "3. **Operations:** Vectors enable computations like addition, subtraction, and scaling, which are useful for tasks like analogy generation.\n",
        "\n",
        "**1.3.2 Basic Concepts of Vectors**\n",
        "1. **Magnitude:** The length of a vector.\n",
        "2. **Direction:** The orientation of the vector in space.\n",
        "3. **Operations:**\n",
        "   - Addition and subtraction of vectors.\n",
        "   - Dot product (used in cosine similarity).\n",
        "   - Scaling (multiplying a vector by a scalar).\n",
        "\n",
        "**1.3.3 Visualizing Vectors**\n",
        "Vectors can be visualized in 2D or 3D space. For example:\n",
        "- A word like \"king\" might be represented as a vector [0.8, 0.6].\n",
        "- A word like \"queen\" might be represented as [0.7, 0.7].\n",
        "\n",
        "**1.3.4 Practical Python Code for Vectors**\n",
        "\n",
        "**Python Code: Basic Operations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt0u7qx__w-R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Magnitude of vector_a: 3.605551275463989\n",
            "Sum of vector_a and vector_b: [6 4]\n",
            "Difference of vector_a and vector_b: [-2  2]\n",
            "Dot product of vector_a and vector_b: 11\n",
            "Scaled vector_a: [4 6]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define vectors\n",
        "vector_a = np.array([2, 3])\n",
        "vector_b = np.array([4, 1])\n",
        "\n",
        "# Magnitude of a vector\n",
        "magnitude_a = np.linalg.norm(vector_a)\n",
        "print(\"Magnitude of vector_a:\", magnitude_a)\n",
        "\n",
        "# Addition of vectors\n",
        "vector_sum = vector_a + vector_b\n",
        "print(\"Sum of vector_a and vector_b:\", vector_sum)\n",
        "\n",
        "# Subtraction of vectors\n",
        "vector_diff = vector_a - vector_b\n",
        "print(\"Difference of vector_a and vector_b:\", vector_diff)\n",
        "\n",
        "# Dot product\n",
        "dot_product = np.dot(vector_a, vector_b)\n",
        "print(\"Dot product of vector_a and vector_b:\", dot_product)\n",
        "\n",
        "# Scaling a vector\n",
        "scalar = 2\n",
        "scaled_vector = scalar * vector_a\n",
        "print(\"Scaled vector_a:\", scaled_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jj2gxJ0_w-R"
      },
      "source": [
        "**Python Code: Cosine Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ0VcmZD_w-R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between vector_c and vector_d: 0.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Example vectors\n",
        "vector_c = np.array([1, 0])\n",
        "vector_d = np.array([0, 1])\n",
        "\n",
        "# Reshape vectors to 2D arrays (required for cosine similarity)\n",
        "similarity = cosine_similarity([vector_c], [vector_d])\n",
        "print(\"Cosine similarity between vector_c and vector_d:\", similarity[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO7rizW__w-S"
      },
      "source": [
        "**1.3.5 Key Insights for NLP**\n",
        "1. Vectors allow us to represent words in a way that computers can process.\n",
        "2. Operations like the dot product and cosine similarity enable the measurement of relationships between words.\n",
        "3. Scaling and combining vectors can help derive new relationships (e.g., \"king - man + woman = queen\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z49QwMzB_w-S"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF-5VHnx_w-S"
      },
      "source": [
        "\n",
        "#### **1.4 Introduction to Word Embeddings**\n",
        "Traditional methods like BoW and TF-IDF fail to capture the semantic meaning of words. Word embeddings solve this by representing words as dense numerical vectors in a continuous vector space.\n",
        "\n",
        "**Why Word Embeddings?**\n",
        "- Words with similar meanings have similar vector representations.\n",
        "- Captures relationships like \"king - man + woman = queen.\"\n",
        "\n",
        "**Example: Cosine Similarity of Word Vectors**\n",
        "- Cosine similarity measures how similar two word vectors are in terms of direction.\n",
        "\n",
        "**Python Code:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fj81Qxi7_w-S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity between 'king' and 'queen': 0.9899494936611666\n",
            "Similarity between 'man' and 'woman': 0.9374252720097653\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Example word embeddings (hypothetical)\n",
        "word_embeddings = {\n",
        "    \"king\": np.array([0.8, 0.6]),\n",
        "    \"queen\": np.array([0.7, 0.7]),\n",
        "    \"man\": np.array([0.5, 0.3]),\n",
        "    \"woman\": np.array([0.4, 0.5])\n",
        "}\n",
        "\n",
        "# Cosine Similarity\n",
        "def calculate_cosine_similarity(word1, word2):\n",
        "    vec1 = word_embeddings[word1]\n",
        "    vec2 = word_embeddings[word2]\n",
        "    similarity = cosine_similarity([vec1], [vec2])\n",
        "    return similarity[0][0]\n",
        "\n",
        "# Example Comparisons\n",
        "print(\"Similarity between 'king' and 'queen':\", calculate_cosine_similarity(\"king\", \"queen\"))\n",
        "print(\"Similarity between 'man' and 'woman':\", calculate_cosine_similarity(\"man\", \"woman\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJxyVtT-_w-S"
      },
      "source": [
        "### **Section 1 Summary**\n",
        "1. NLP bridges the gap between human language and computers.\n",
        "2. Text preprocessing is essential for cleaning and preparing data.\n",
        "3. BoW and TF-IDF are basic text vectorization techniques but lack semantic understanding.\n",
        "4. Word embeddings provide semantic meaning, enabling better NLP applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Lecture 3: NLP for Business Applications**  \n",
        "\n",
        "### **1. Sentiment Analysis for Customer Reviews**  \n",
        "#### **Problem:**  \n",
        "Businesses receive thousands of online reviews daily. Manually analyzing customer sentiment is time-consuming and impractical.  \n",
        "\n",
        "#### **Solution:**  \n",
        "NLP can automatically classify customer reviews into **positive, negative, or neutral** sentiments.  \n",
        "\n",
        "#### **Business Impact:**  \n",
        "- Helps companies understand customer satisfaction trends.  \n",
        "- Identifies pain points to improve products/services.  \n",
        "- Enables real-time feedback monitoring.  \n",
        "\n",
        "#### **Example: Sentiment Classification Using Naïve Bayes**  \n",
        "```python\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Sample Data\n",
        "X_train = [\"I love this product!\", \"This is the worst experience ever\", \"It's okay, nothing special\"]\n",
        "y_train = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Build Model\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "print(model.predict([\"Amazing quality!\"]))  # Output: ['positive']\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Resume Screening for HR Automation**  \n",
        "#### **Problem:**  \n",
        "Recruiters manually review hundreds of resumes to match candidates to job descriptions. This is inefficient and prone to bias.  \n",
        "\n",
        "#### **Solution:**  \n",
        "NLP can **extract skills** from resumes and calculate similarity scores between resumes and job descriptions.  \n",
        "\n",
        "#### **Business Impact:**  \n",
        "- Saves HR departments **time and effort** in recruitment.  \n",
        "- Improves candidate-job **matching accuracy**.  \n",
        "- Reduces human bias in resume evaluation.  \n",
        "\n",
        "#### **Example: Resume Matching Using Cosine Similarity**  \n",
        "```python\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "job_description = \"Looking for a data scientist skilled in Python, NLP, and machine learning.\"\n",
        "resume = \"Experienced data scientist with expertise in Python and NLP.\"\n",
        "\n",
        "vectorizer = CountVectorizer().fit_transform([job_description, resume])\n",
        "similarity = cosine_similarity(vectorizer)[0][1]\n",
        "\n",
        "print(f\"Resume Similarity Score: {similarity:.2f}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Automating Customer Support with Chatbots**  \n",
        "#### **Problem:**  \n",
        "Customer support teams handle repetitive inquiries, leading to high costs and delays.  \n",
        "\n",
        "#### **Solution:**  \n",
        "NLP-powered chatbots **understand user queries** and **respond with predefined answers**.  \n",
        "\n",
        "#### **Business Impact:**  \n",
        "- Reduces customer support costs.  \n",
        "- Provides instant responses to frequently asked questions (FAQs).  \n",
        "- Enhances user experience with 24/7 availability.  \n",
        "\n",
        "#### **Example: FAQ Chatbot Using Logistic Regression**  \n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "queries = [\"What are your working hours?\", \"How can I reset my password?\", \"What is your refund policy?\"]\n",
        "responses = [\"We are open from 9 AM to 6 PM.\", \"Click 'Forgot Password' to reset it.\", \"Refunds take 5 days.\"]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(queries)\n",
        "y = np.array(responses)\n",
        "\n",
        "model = LogisticRegression().fit(X, y)\n",
        "\n",
        "print(model.predict(vectorizer.transform([\"How do I change my password?\"])))  \n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Extracting Key Information from Business Documents**  \n",
        "#### **Problem:**  \n",
        "Organizations need to quickly extract key insights from lengthy business reports and contracts.  \n",
        "\n",
        "#### **Solution:**  \n",
        "NLP automates **keyword extraction** and **summarization**.  \n",
        "\n",
        "#### **Business Impact:**  \n",
        "- Saves time in document review.  \n",
        "- Helps decision-makers find **critical information** faster.  \n",
        "- Improves compliance and contract analysis.  \n",
        "\n",
        "#### **Example: Keyword Extraction Using TF-IDF**  \n",
        "```python\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "document = [\"Our company specializes in AI, machine learning, and NLP solutions.\"]\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "tfidf_matrix = vectorizer.fit_transform(document)\n",
        "\n",
        "keywords = vectorizer.get_feature_names_out()\n",
        "print(\"Extracted Keywords:\", keywords)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Spam Detection in Emails**  \n",
        "#### **Problem:**  \n",
        "Companies receive thousands of spam emails, leading to wasted time and security risks.  \n",
        "\n",
        "#### **Solution:**  \n",
        "NLP can **detect spam patterns** using machine learning models.  \n",
        "\n",
        "#### **Business Impact:**  \n",
        "- Improves email security.  \n",
        "- Saves time by filtering out irrelevant messages.  \n",
        "- Reduces exposure to phishing attacks.  \n",
        "\n",
        "#### **Example: Spam Classification Using Naïve Bayes**  \n",
        "```python\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Sample emails\n",
        "emails = [\"Congratulations! You won a lottery.\", \"Meeting scheduled at 10 AM.\"]\n",
        "labels = [\"spam\", \"ham\"]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(emails)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X, labels)\n",
        "\n",
        "new_email = [\"Claim your prize now!\"]\n",
        "print(model.predict(vectorizer.transform(new_email)))  # Output: ['spam']\n",
        "```\n",
        "### **Summary**  \n",
        "✅ NLP enables **automation** and **insight extraction** in business applications.  \n",
        "✅ Traditional NLP techniques like **tokenization, vectorization, and classification** solve real-world problems.  \n",
        "✅ Next Step: **Deep Learning NLP (BERT, GPT)** for more **advanced** language understanding.  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
